{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "527f8e31",
   "metadata": {},
   "source": [
    "Source: https://python.langchain.com/docs/tutorials/llm_chain/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3515867",
   "metadata": {},
   "source": [
    "- get your llm api key\n",
    "- Use Groq - its free\n",
    "- save it in .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01dc67e",
   "metadata": {},
   "source": [
    "Also do these steps in .env\n",
    "\n",
    "LANGSMITH_TRACING=\"true\"\n",
    "LANGSMITH_API_KEY=\"...\"\n",
    "LANGSMITH_PROJECT=\"default\" # or any other project name"
   ]
  },
  {
   "cell_type": "code",
   "id": "682c4c87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T09:43:32.762878Z",
     "start_time": "2025-08-26T09:43:32.754367Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "afe84af3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T09:43:32.777636Z",
     "start_time": "2025-08-26T09:43:32.776138Z"
    }
   },
   "source": [
    "# !pip install -qU \"langchain[groq]\""
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "a0e461e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T09:43:32.975697Z",
     "start_time": "2025-08-26T09:43:32.783006Z"
    }
   },
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"llama3-8b-8192\", model_provider=\"groq\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nithurshen/SNU/MAT496/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "a6f93f75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T09:43:33.178858Z",
     "start_time": "2025-08-26T09:43:32.983747Z"
    }
   },
   "source": [
    "# A simple model call\n",
    "\n",
    "model.invoke(\"Whats up?\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Not much! I'm just an AI, I don't have personal experiences or emotions like humans do, but I'm here to help you with any questions or topics you'd like to discuss. How about you?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 13, 'total_tokens': 57, 'completion_time': 0.041603786, 'prompt_time': 0.002362504, 'queue_time': 0.043632486, 'total_time': 0.04396629}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_4b5fbf0ced', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--dab6e154-42eb-402a-a218-db9448b6bde2-0', usage_metadata={'input_tokens': 13, 'output_tokens': 44, 'total_tokens': 57})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "42416cbd",
   "metadata": {},
   "source": [
    "[Exercise] Play along. Give bigger and bigger prompts"
   ]
  },
  {
   "cell_type": "code",
   "id": "da2738af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T09:43:33.531110Z",
     "start_time": "2025-08-26T09:43:33.182320Z"
    }
   },
   "source": [
    "model.invoke(\"Who are you?\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I am LLaMA, an AI assistant developed by Meta AI that can understand and respond to human input in a conversational manner. I'm not a human, but a computer program designed to simulate conversation and answer questions to the best of my knowledge based on my training data.\\n\\nI was trained on a massive dataset of text from the internet and can generate responses to a wide range of topics and questions. I can understand natural language, recognize context, and even generate text in response to a given prompt or question.\\n\\nMy capabilities include:\\n\\n1. Answering questions: I can provide information on a wide range of topics, from science and history to entertainment and culture.\\n2. Generating text: I can create text based on a given prompt, topic, or style.\\n3. Translation: I can translate text from one language to another.\\n4. Summarization: I can summarize long pieces of text into shorter, more digestible versions.\\n5. Conversation: I can engage in natural-sounding conversations, using context and understanding to respond to questions and statements.\\n\\nI'm constantly learning and improving, so the more we chat, the better I'll become at understanding and responding to your questions and topics!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 241, 'prompt_tokens': 14, 'total_tokens': 255, 'completion_time': 0.229929051, 'prompt_time': 0.003789316, 'queue_time': 0.056157334, 'total_time': 0.233718367}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_4b5fbf0ced', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--9f3c954a-547e-4bc4-b0b0-6692501d2319-0', usage_metadata={'input_tokens': 14, 'output_tokens': 241, 'total_tokens': 255})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "a7f4578d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T09:43:34.456551Z",
     "start_time": "2025-08-26T09:43:33.538515Z"
    }
   },
   "source": [
    "response = model.invoke(\"\"\" Write a python code which can multiply two matrix of arbitrary but compatible order. The code should throw exception if the matrix dimentsions are not compatible for multiplication             \n",
    "             \"\"\")\n",
    "\n",
    "response"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Here is a Python code that multiplies two matrices of arbitrary but compatible order:\\n```\\ndef multiply_matrices(A, B):\\n    # Get the dimensions of the matrices\\n    rows_A, cols_A = len(A), len(A[0])\\n    rows_B, cols_B = len(B), len(B[0])\\n\\n    # Check if the matrices are compatible for multiplication\\n    if cols_A != rows_B:\\n        raise ValueError(\"Incompatible matrix dimensions for multiplication\")\\n\\n    # Create the result matrix with zeros\\n    C = [[0 for _ in range(cols_B)] for _ in range(rows_A)]\\n\\n    # Multiply the matrices\\n    for i in range(rows_A):\\n        for j in range(cols_B):\\n            for k in range(cols_A):  # or rows_B\\n                C[i][j] += A[i][k] * B[k][j]\\n\\n    return C\\n\\n# Example usage:\\nA = [[1, 2, 3], [4, 5, 6]]\\nB = [[7, 8], [9, 10], [11, 12]]\\nC = multiply_matrices(A, B)\\nprint(C)  # Output: [[58, 64], [139, 154]]\\n```\\nHere\\'s an explanation of the code:\\n\\n1. We first get the dimensions of the input matrices `A` and `B` using the `len()` function.\\n2. We check if the matrices are compatible for multiplication by checking if the number of columns in `A` is equal to the number of rows in `B`. If this condition is not met, we raise a `ValueError`.\\n3. We create a new matrix `C` with the same number of rows as `A` and the same number of columns as `B`, filled with zeros.\\n4. We then iterate over the rows and columns of `C` and perform the matrix multiplication using three nested loops.\\n5. In each iteration, we multiply the corresponding elements of `A` and `B` and add them to the corresponding element of `C`.\\n6. Finally, we return the resulting matrix `C`.\\n\\nNote that this implementation assumes that the input matrices are lists of lists, where each inner list represents a row in the matrix.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 459, 'prompt_tokens': 43, 'total_tokens': 502, 'completion_time': 0.453761685, 'prompt_time': 0.01072507, 'queue_time': 0.382033158, 'total_time': 0.464486755}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_4b5fbf0ced', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--90787341-64fe-4213-b246-2bb5691a6bfd-0', usage_metadata={'input_tokens': 43, 'output_tokens': 459, 'total_tokens': 502})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "17c8c30d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T09:43:34.464399Z",
     "start_time": "2025-08-26T09:43:34.462712Z"
    }
   },
   "source": [
    "print(response.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a Python code that multiplies two matrices of arbitrary but compatible order:\n",
      "```\n",
      "def multiply_matrices(A, B):\n",
      "    # Get the dimensions of the matrices\n",
      "    rows_A, cols_A = len(A), len(A[0])\n",
      "    rows_B, cols_B = len(B), len(B[0])\n",
      "\n",
      "    # Check if the matrices are compatible for multiplication\n",
      "    if cols_A != rows_B:\n",
      "        raise ValueError(\"Incompatible matrix dimensions for multiplication\")\n",
      "\n",
      "    # Create the result matrix with zeros\n",
      "    C = [[0 for _ in range(cols_B)] for _ in range(rows_A)]\n",
      "\n",
      "    # Multiply the matrices\n",
      "    for i in range(rows_A):\n",
      "        for j in range(cols_B):\n",
      "            for k in range(cols_A):  # or rows_B\n",
      "                C[i][j] += A[i][k] * B[k][j]\n",
      "\n",
      "    return C\n",
      "\n",
      "# Example usage:\n",
      "A = [[1, 2, 3], [4, 5, 6]]\n",
      "B = [[7, 8], [9, 10], [11, 12]]\n",
      "C = multiply_matrices(A, B)\n",
      "print(C)  # Output: [[58, 64], [139, 154]]\n",
      "```\n",
      "Here's an explanation of the code:\n",
      "\n",
      "1. We first get the dimensions of the input matrices `A` and `B` using the `len()` function.\n",
      "2. We check if the matrices are compatible for multiplication by checking if the number of columns in `A` is equal to the number of rows in `B`. If this condition is not met, we raise a `ValueError`.\n",
      "3. We create a new matrix `C` with the same number of rows as `A` and the same number of columns as `B`, filled with zeros.\n",
      "4. We then iterate over the rows and columns of `C` and perform the matrix multiplication using three nested loops.\n",
      "5. In each iteration, we multiply the corresponding elements of `A` and `B` and add them to the corresponding element of `C`.\n",
      "6. Finally, we return the resulting matrix `C`.\n",
      "\n",
      "Note that this implementation assumes that the input matrices are lists of lists, where each inner list represents a row in the matrix.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "8b215da3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T09:43:34.681008Z",
     "start_time": "2025-08-26T09:43:34.471008Z"
    }
   },
   "source": [
    "# invoking to build a converstation style call\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into Bengali\"), # try punjabi, or any other Indian language\n",
    "    HumanMessage(\"hi!\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='হ্যালো! (Halo!)', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 25, 'total_tokens': 39, 'completion_time': 0.01378058, 'prompt_time': 0.006870095, 'queue_time': 0.122228565, 'total_time': 0.020650675}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_4b5fbf0ced', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--210ff2b1-f23d-43cb-81d3-fd97ed2a8761-0', usage_metadata={'input_tokens': 25, 'output_tokens': 14, 'total_tokens': 39})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "9efe5fb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T09:43:35.123327Z",
     "start_time": "2025-08-26T09:43:34.689142Z"
    }
   },
   "source": [
    "messages = [\n",
    "    SystemMessage(\"Generate python code for given tasks\"),\n",
    "    HumanMessage(\"Find max of given n numbers\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "\n",
    "response"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Here is a Python code snippet to find the maximum of n numbers:\\n```\\ndef find_max(n, numbers):\\n    return max(numbers)\\n\\n# Example usage:\\nn = int(input(\"Enter the number of numbers: \"))\\nnumbers = [int(x) for x in input(\"Enter the numbers separated by space: \").split()]\\nmax_num = find_max(n, numbers)\\nprint(\"The maximum number is:\", max_num)\\n```\\nHere\\'s how the code works:\\n\\n1. The `find_max` function takes two arguments: `n` (the number of numbers) and `numbers` (a list of numbers).\\n2. The `max` function is used to find the maximum value in the `numbers` list.\\n3. In the example usage, the user is prompted to enter the number of numbers and then the numbers themselves, separated by spaces.\\n4. The `find_max` function is called with the user-input values, and the maximum number is printed to the console.\\n\\nFor example, if the user enters `3` as the number of numbers and `1 2 3` as the numbers themselves, the output would be `The maximum number is: 3`.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 240, 'prompt_tokens': 27, 'total_tokens': 267, 'completion_time': 0.224770984, 'prompt_time': 0.006575281, 'queue_time': 0.131190209, 'total_time': 0.231346265}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_4b5fbf0ced', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--cd66a191-7541-4b28-bc7a-432d252cfe96-0', usage_metadata={'input_tokens': 27, 'output_tokens': 240, 'total_tokens': 267})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "d36098aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T09:43:35.133241Z",
     "start_time": "2025-08-26T09:43:35.131485Z"
    }
   },
   "source": [
    "print(response.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a Python code snippet to find the maximum of n numbers:\n",
      "```\n",
      "def find_max(n, numbers):\n",
      "    return max(numbers)\n",
      "\n",
      "# Example usage:\n",
      "n = int(input(\"Enter the number of numbers: \"))\n",
      "numbers = [int(x) for x in input(\"Enter the numbers separated by space: \").split()]\n",
      "max_num = find_max(n, numbers)\n",
      "print(\"The maximum number is:\", max_num)\n",
      "```\n",
      "Here's how the code works:\n",
      "\n",
      "1. The `find_max` function takes two arguments: `n` (the number of numbers) and `numbers` (a list of numbers).\n",
      "2. The `max` function is used to find the maximum value in the `numbers` list.\n",
      "3. In the example usage, the user is prompted to enter the number of numbers and then the numbers themselves, separated by spaces.\n",
      "4. The `find_max` function is called with the user-input values, and the maximum number is printed to the console.\n",
      "\n",
      "For example, if the user enters `3` as the number of numbers and `1 2 3` as the numbers themselves, the output would be `The maximum number is: 3`.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "39caa649",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T09:43:38.060003Z",
     "start_time": "2025-08-26T09:43:35.137036Z"
    }
   },
   "source": [
    "# streaming example\n",
    "import time\n",
    "\n",
    "for token in model.stream(\"hi\"):\n",
    "    time.sleep(0.1)\n",
    "    print(token.content, end=\"|\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Hi|!| It|'s| nice| to| meet| you|.| Is| there| something| I| can| help| you| with|,| or| would| you| like| to| chat|?||"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "6837d022",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T09:43:38.065108Z",
     "start_time": "2025-08-26T09:43:38.063649Z"
    }
   },
   "source": [
    "# Class discussion point: What is an LLM as a program"
   ],
   "outputs": [],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mat496-monsoon2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
